#!/usr/bin/env python3
"""
ä½¿ç”¨åŸå§‹2by4-pretrain-acc-examplesçš„FP8SparseLinearæµ‹è¯•æ€§èƒ½
å¤ç°ç”¨æˆ·è®°å½•ä¸­çš„æˆåŠŸæ¡ˆä¾‹
"""

import sys
import os
sys.path.insert(0, '/home/rtx3090/code_jiaxi/2by4-pretrain-acc-examples/v2/nanoGPT')

import torch
import torch.nn as nn
import time

# Import original 2by4 implementation
try:
    from sparse_ops import FP8SparseLinear
    print("âœ… æˆåŠŸå¯¼å…¥åŸå§‹2by4-pretrain-acc-examplesçš„FP8SparseLinear")
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥åŸå§‹FP8SparseLinear: {e}")
    sys.exit(1)

def test_original_fp8_sparse_linear():
    """æµ‹è¯•åŸå§‹çš„FP8SparseLinearå±‚æ€§èƒ½"""
    print("=== æµ‹è¯•åŸå§‹FP8SparseLinearæ€§èƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•å‚æ•°ï¼ˆä¸æ‚¨è®°å½•ä¸­ç›¸åŒï¼‰
    batch_size = 8
    seq_len = 1024
    hidden_size = 768
    intermediate_size = hidden_size * 4  # 3072
    
    input_tensor = torch.randn(batch_size, seq_len, hidden_size).cuda()
    
    print(f"æµ‹è¯•é…ç½®: batch_size={batch_size}, seq_len={seq_len}")
    print(f"çŸ©é˜µå°ºå¯¸: {hidden_size} -> {intermediate_size}")
    
    # 1. åˆ›å»ºåŸå§‹FP8SparseLinearå±‚
    print("\n1. åˆ›å»ºFP8SparseLinearå±‚...")
    sparse_layer = FP8SparseLinear(hidden_size, intermediate_size).cuda()
    sparse_layer.init_scale()
    
    # æ£€æŸ¥ç¨€ç–åº¦
    sparse_weights = sparse_layer.get_sparse_weights()
    sparsity = (sparse_weights == 0).float().mean().item()
    print(f"   ç¨€ç–åº¦: {sparsity:.1%}")
    
    # 2. åˆ›å»ºæ™®é€šLinearå±‚
    print("\n2. åˆ›å»ºæ™®é€šLinearå±‚...")
    dense_layer = nn.Linear(hidden_size, intermediate_size).cuda()
    
    def test_layer_performance(layer, name, iterations=50):
        """æµ‹è¯•å±‚æ€§èƒ½"""
        layer.eval()
        
        # Warmup
        for _ in range(10):
            with torch.no_grad():
                _ = layer(input_tensor)
        
        torch.cuda.synchronize()
        start_time = time.time()
        
        for _ in range(iterations):
            with torch.no_grad():
                output = layer(input_tensor)
        
        torch.cuda.synchronize()
        end_time = time.time()
        
        avg_time = (end_time - start_time) / iterations * 1000  # ms
        print(f"   {name}å¹³å‡æ—¶é—´: {avg_time:.2f}ms")
        return avg_time
    
    # 3. æµ‹è¯•æ€§èƒ½
    print("\n3. æ€§èƒ½æµ‹è¯•...")
    sparse_time = test_layer_performance(sparse_layer, "FP8SparseLinear")
    dense_time = test_layer_performance(dense_layer, "Linear")
    
    # 4. ç»“æœåˆ†æ
    speedup = dense_time / sparse_time
    
    print(f"\n=== åŸå§‹FP8SparseLinearæ€§èƒ½å¯¹æ¯” ===")
    print(f"FP8SparseLinearæ—¶é—´: {sparse_time:.2f}ms")
    print(f"Linearæ—¶é—´: {dense_time:.2f}ms")
    print(f"åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"å®é™…ç¨€ç–åº¦: {sparsity:.1%}")
    
    if sparsity < 0.4:
        print("âš ï¸  è­¦å‘Šï¼šç¨€ç–åº¦ä½äº40%ï¼Œ2:4ç¨€ç–åŒ–å¯èƒ½æ²¡æœ‰æ­£ç¡®åº”ç”¨")
    
    if speedup > 1.5:
        print("âœ… 2:4ç¨€ç–åŒ–åŠ é€ŸæˆåŠŸï¼")
        return True
    elif speedup > 1.0:
        print("âœ… 2:4ç¨€ç–åŒ–æœ‰è½»å¾®åŠ é€Ÿ")
        return True
    else:
        print("âŒ 2:4ç¨€ç–åŒ–æ²¡æœ‰åŠ é€Ÿæ•ˆæœ")
        return False


def test_pure_sparse_matmul():
    """æµ‹è¯•çº¯ç¨€ç–çŸ©é˜µä¹˜æ³•"""
    print("\n" + "="*50)
    print("æµ‹è¯•çº¯ç¨€ç–çŸ©é˜µä¹˜æ³•")
    print("="*50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 8
    seq_len = 1024
    hidden_size = 768
    
    x = torch.randn(batch_size, seq_len, hidden_size).cuda()
    
    # åˆ›å»ºFP8SparseLinearå±‚å¹¶è·å–ç¨€ç–æƒé‡
    sparse_layer = FP8SparseLinear(hidden_size, hidden_size).cuda()
    sparse_layer.init_scale()
    
    # è·å–ç¨€ç–æƒé‡ï¼ˆé¢„è®¡ç®—ï¼‰
    sparse_weight = sparse_layer.get_sparse_weights()
    bias = sparse_layer.bias
    
    # åˆ›å»ºå¯†é›†æƒé‡
    dense_weight = torch.randn_like(sparse_weight)
    
    # å¯¼å…¥ç¨€ç–æ“ä½œ
    from sparse_ops import fp8_linear
    
    def test_matmul_performance(name, weight, use_sparse=False, iterations=100):
        # Warmup
        for _ in range(20):
            if use_sparse:
                output = fp8_linear.apply(x, weight, bias)
            else:
                output = torch.matmul(x, weight.t()) + bias
        
        torch.cuda.synchronize()
        start_time = time.time()
        
        for _ in range(iterations):
            if use_sparse:
                output = fp8_linear.apply(x, weight, bias)
            else:
                output = torch.matmul(x, weight.t()) + bias
        
        torch.cuda.synchronize()
        end_time = time.time()
        
        avg_time = (end_time - start_time) / iterations * 1000
        print(f"{name}çŸ©é˜µä¹˜æ³•å¹³å‡æ—¶é—´: {avg_time:.3f}ms")
        return avg_time
    
    # æµ‹è¯•ç¨€ç–å’Œå¯†é›†çŸ©é˜µä¹˜æ³•
    sparse_matmul_time = test_matmul_performance("ç¨€ç–", sparse_weight, use_sparse=True)
    dense_matmul_time = test_matmul_performance("å¯†é›†", dense_weight, use_sparse=False)
    
    speedup = dense_matmul_time / sparse_matmul_time
    sparsity = (sparse_weight == 0).float().mean().item()
    
    print(f"\n=== çº¯çŸ©é˜µä¹˜æ³•æ€§èƒ½å¯¹æ¯” ===")
    print(f"ç¨€ç–çŸ©é˜µä¹˜æ³•: {sparse_matmul_time:.3f}ms")
    print(f"å¯†é›†çŸ©é˜µä¹˜æ³•: {dense_matmul_time:.3f}ms")
    print(f"åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"ç¨€ç–åº¦: {sparsity:.1%}")
    
    return speedup > 1.2


def main():
    print("ğŸ§ª åŸå§‹2by4-pretrain-acc-examplesæ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    # æ£€æŸ¥GPUä¿¡æ¯
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"GPU: {gpu_name}")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        return
    
    # è¿è¡Œæµ‹è¯•
    test1_passed = test_original_fp8_sparse_linear()
    test2_passed = test_pure_sparse_matmul()
    
    print(f"\n" + "="*60)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"FP8SparseLinearå±‚æµ‹è¯•: {'âœ… é€šè¿‡' if test1_passed else 'âŒ å¤±è´¥'}")
    print(f"çº¯çŸ©é˜µä¹˜æ³•æµ‹è¯•: {'âœ… é€šè¿‡' if test2_passed else 'âŒ å¤±è´¥'}")
    
    if test1_passed and test2_passed:
        print("\nğŸ‰ åŸå§‹2by4å®ç°ç¡®å®æœ‰åŠ é€Ÿæ•ˆæœï¼")
        print("è¿™è¯´æ˜RTX 3090æ”¯æŒ2:4ç¨€ç–åŠ é€Ÿï¼Œæˆ‘ä»¬çš„LOROå®ç°å¯èƒ½éœ€è¦è°ƒæ•´")
    elif test1_passed or test2_passed:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æ˜¾ç¤ºæœ‰åŠ é€Ÿæ•ˆæœ")
    else:
        print("\nâŒ æµ‹è¯•æœªæ˜¾ç¤ºæ˜æ˜¾åŠ é€Ÿæ•ˆæœ")


if __name__ == "__main__":
    main() 