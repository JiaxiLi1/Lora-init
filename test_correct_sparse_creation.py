#!/usr/bin/env python3
"""
ä½¿ç”¨æ­£ç¡®çš„soft_threshold24_tritonåˆ›å»ºç¨€ç–çŸ©é˜µè¿›è¡Œæµ‹è¯•
æ¯”è¾ƒä¸åŒçŸ©é˜µå°ºå¯¸çš„2:4åŠ é€Ÿæ•ˆæœ
"""

import sys
import os
sys.path.insert(0, '/home/rtx3090/code_jiaxi/2by4-pretrain-acc-examples/v2/nanoGPT')

import torch
import time
from sparse_ops import fp8_linear
from sparse import soft_threshold24_triton

def create_correct_24_sparse_weight(shape):
    """ä½¿ç”¨æ­£ç¡®çš„soft_threshold24_tritonåˆ›å»º2:4ç¨€ç–æƒé‡"""
    weight = torch.randn(shape).cuda()
    # ä½¿ç”¨2by4é¡¹ç›®çš„æ­£ç¡®å®ç°
    weight_sparse, mask = soft_threshold24_triton(weight)
    return weight_sparse

def test_sparse_creation():
    """æµ‹è¯•ç¨€ç–çŸ©é˜µåˆ›å»ºæ˜¯å¦æ­£ç¡®"""
    print("ğŸ”¬ éªŒè¯ç¨€ç–çŸ©é˜µåˆ›å»º")
    print("="*50)
    
    weight = torch.randn(256, 768).cuda()
    sparse_weight = create_correct_24_sparse_weight((256, 768))
    
    # æ£€æŸ¥ç¨€ç–åº¦
    sparsity = (sparse_weight == 0).float().mean().item()
    print(f"ç¨€ç–åº¦: {sparsity:.1%}")
    
    # æ£€æŸ¥2:4æ¨¡å¼
    reshaped = sparse_weight.view(-1, 4)
    nonzero_counts = (reshaped != 0).sum(dim=1)
    perfect_24 = torch.all(nonzero_counts <= 2)
    print(f"2:4æ¨¡å¼: {'âœ… æ­£ç¡®' if perfect_24 else 'âŒ é”™è¯¯'}")
    
    # æ£€æŸ¥éé›¶å…ƒç´ åˆ†å¸ƒ
    print(f"æ¯4ä¸ªå…ƒç´ çš„éé›¶è®¡æ•°åˆ†å¸ƒ:")
    for i in range(3):
        count = (nonzero_counts == i).sum().item()
        print(f"  {i}ä¸ªéé›¶: {count}")
    
    return sparse_weight

def test_matrix_size_performance_correct(in_features, out_features, name):
    """ä½¿ç”¨æ­£ç¡®çš„ç¨€ç–åˆ›å»ºæ–¹æ³•æµ‹è¯•æ€§èƒ½"""
    print(f"\n=== æµ‹è¯•{name} {in_features}Ã—{out_features} ===")
    
    batch_size = 8
    seq_len = 1024
    x = torch.randn(batch_size, seq_len, in_features).cuda()
    
    # ä½¿ç”¨æ­£ç¡®çš„soft_thresholdåˆ›å»ºç¨€ç–æƒé‡
    sparse_weight = create_correct_24_sparse_weight((out_features, in_features))
    sparsity = (sparse_weight == 0).float().mean().item()
    
    # åˆ›å»ºå¯†é›†æƒé‡
    dense_weight = torch.randn(out_features, in_features).cuda()
    
    iterations = 100
    warmup = 20
    
    # æµ‹è¯•ç¨€ç–çŸ©é˜µä¹˜æ³•
    print("   æµ‹è¯•ç¨€ç–çŸ©é˜µä¹˜æ³•...")
    for _ in range(warmup):
        _ = fp8_linear.apply(x, sparse_weight, None)
    
    torch.cuda.synchronize()
    start_time = time.time()
    for _ in range(iterations):
        _ = fp8_linear.apply(x, sparse_weight, None)
    torch.cuda.synchronize()
    sparse_time = (time.time() - start_time) / iterations * 1000
    
    # æµ‹è¯•å¯†é›†çŸ©é˜µä¹˜æ³•
    print("   æµ‹è¯•å¯†é›†çŸ©é˜µä¹˜æ³•...")
    for _ in range(warmup):
        _ = torch.matmul(x, dense_weight.t())
    
    torch.cuda.synchronize()
    start_time = time.time()
    for _ in range(iterations):
        _ = torch.matmul(x, dense_weight.t())
    torch.cuda.synchronize()
    dense_time = (time.time() - start_time) / iterations * 1000
    
    speedup = dense_time / sparse_time
    
    print(f"   ç¨€ç–çŸ©é˜µ: {sparse_time:.3f}ms")
    print(f"   å¯†é›†çŸ©é˜µ: {dense_time:.3f}ms") 
    print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"   ç¨€ç–åº¦: {sparsity:.1%}")
    
    return sparse_time, dense_time, speedup

def compare_old_vs_new_sparse_creation():
    """å¯¹æ¯”æˆ‘ä¹‹å‰é”™è¯¯çš„ç¨€ç–åˆ›å»º vs æ­£ç¡®çš„soft_thresholdåˆ›å»º"""
    print("\n" + "="*60)
    print("é”™è¯¯ç¨€ç–åˆ›å»º vs æ­£ç¡®ç¨€ç–åˆ›å»º å¯¹æ¯”")
    print("="*60)
    
    # ä¿®æ­£ï¼šç¡®ä¿çŸ©é˜µç»´åº¦æ­£ç¡®
    in_features = 768
    out_features = 3072
    x = torch.randn(8, 1024, in_features).cuda()
    
    # 1. æˆ‘ä¹‹å‰é”™è¯¯çš„æ–¹æ³•
    print("\n1. é”™è¯¯çš„ç¨€ç–åˆ›å»ºæ–¹æ³• (topk)")
    weight_wrong = torch.randn(out_features, in_features).cuda()  # ä¿®æ­£ç»´åº¦
    weight_flat = weight_wrong.view(-1, 4)
    _, indices = torch.topk(torch.abs(weight_flat), 2, dim=1)
    mask = torch.zeros_like(weight_flat)
    mask.scatter_(1, indices, 1)
    sparse_weight_wrong = (weight_flat * mask).view(out_features, in_features)
    
    sparsity_wrong = (sparse_weight_wrong == 0).float().mean().item()
    print(f"   ç¨€ç–åº¦: {sparsity_wrong:.1%}")
    
    # 2. æ­£ç¡®çš„æ–¹æ³•
    print("\n2. æ­£ç¡®çš„ç¨€ç–åˆ›å»ºæ–¹æ³• (soft_threshold24_triton)")
    sparse_weight_correct = create_correct_24_sparse_weight((out_features, in_features))
    
    sparsity_correct = (sparse_weight_correct == 0).float().mean().item()
    print(f"   ç¨€ç–åº¦: {sparsity_correct:.1%}")
    
    # æ€§èƒ½æµ‹è¯•
    iterations = 50
    warmup = 10
    
    # é”™è¯¯æ–¹æ³•æ€§èƒ½
    for _ in range(warmup):
        _ = fp8_linear.apply(x, sparse_weight_wrong, None)
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = fp8_linear.apply(x, sparse_weight_wrong, None)
    torch.cuda.synchronize()
    wrong_time = (time.time() - start) / iterations * 1000
    
    # æ­£ç¡®æ–¹æ³•æ€§èƒ½
    for _ in range(warmup):
        _ = fp8_linear.apply(x, sparse_weight_correct, None)
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = fp8_linear.apply(x, sparse_weight_correct, None)
    torch.cuda.synchronize()
    correct_time = (time.time() - start) / iterations * 1000
    
    # å¯†é›†å‚ç…§
    dense_weight = torch.randn(out_features, in_features).cuda()
    for _ in range(warmup):
        _ = torch.matmul(x, dense_weight.t())
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = torch.matmul(x, dense_weight.t())
    torch.cuda.synchronize()
    dense_time = (time.time() - start) / iterations * 1000
    
    print(f"\n=== æ€§èƒ½å¯¹æ¯” ===")
    print(f"é”™è¯¯æ–¹æ³•: {wrong_time:.3f}ms (åŠ é€Ÿæ¯”: {dense_time/wrong_time:.2f}x)")
    print(f"æ­£ç¡®æ–¹æ³•: {correct_time:.3f}ms (åŠ é€Ÿæ¯”: {dense_time/correct_time:.2f}x)")
    print(f"å¯†é›†æ–¹æ³•: {dense_time:.3f}ms")
    print(f"æ­£ç¡® vs é”™è¯¯: {wrong_time/correct_time:.2f}x ({'å¿«' if wrong_time > correct_time else 'æ…¢'})")

def test_two_step_matmul_comparison():
    """æµ‹è¯•è¿ç»­ä¸¤æ­¥çŸ©é˜µä¹˜æ³•ï¼šå¯†é›†vsç¨€ç–"""
    print("\n" + "="*60)
    print("è¿ç»­ä¸¤æ­¥çŸ©é˜µä¹˜æ³•å¯¹æ¯”")
    print("="*60)
    
    batch_size = 8
    seq_len = 1024
    hidden_size = 512
    intermediate_size = 512
    rank = 128
    
    x = torch.randn(batch_size, seq_len, hidden_size).cuda()
    
    # åˆ›å»ºæƒé‡
    # ç¬¬ä¸€æ­¥ï¼š768 -> 64
    weight_in_dense = torch.randn(rank, hidden_size).cuda()
    weight_in_sparse = create_correct_24_sparse_weight((rank, hidden_size))
    
    # ç¬¬äºŒæ­¥ï¼š64 -> 3072
    weight_out_dense = torch.randn(intermediate_size, rank).cuda()
    weight_out_sparse = create_correct_24_sparse_weight((intermediate_size, rank))
    
    iterations = 100
    warmup = 20
    
    print(f"\næµ‹è¯•é…ç½®:")
    print(f"  è¾“å…¥: {batch_size}Ã—{seq_len}Ã—{hidden_size}")
    print(f"  ç¬¬ä¸€æ­¥: {hidden_size}â†’{rank}")
    print(f"  ç¬¬äºŒæ­¥: {rank}â†’{intermediate_size}")
    print(f"  è¿­ä»£æ¬¡æ•°: {iterations}")
    
    # 1. è¿ç»­ä¸¤æ­¥å¯†é›†çŸ©é˜µä¹˜æ³•
    print(f"\n1. è¿ç»­ä¸¤æ­¥å¯†é›†çŸ©é˜µä¹˜æ³•")
    for _ in range(warmup):
        x_proj = torch.matmul(x, weight_in_dense.t())
        _ = torch.matmul(x_proj, weight_out_dense.t())
    
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        x_proj = torch.matmul(x, weight_in_dense.t())
        output = torch.matmul(x_proj, weight_out_dense.t())
    torch.cuda.synchronize()
    dense_two_step_time = (time.time() - start) / iterations * 1000
    
    print(f"   å¯†é›†ä¸¤æ­¥æ€»æ—¶é—´: {dense_two_step_time:.3f}ms")
    
    # 2. è¿ç»­ä¸¤æ­¥ç¨€ç–çŸ©é˜µä¹˜æ³•
    print(f"\n2. è¿ç»­ä¸¤æ­¥ç¨€ç–çŸ©é˜µä¹˜æ³•")
    for _ in range(warmup):
        x_proj = fp8_linear.apply(x, weight_in_sparse, None)
        _ = fp8_linear.apply(x_proj, weight_out_sparse, None)
    
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        x_proj = fp8_linear.apply(x, weight_in_sparse, None)
        output = fp8_linear.apply(x_proj, weight_out_sparse, None)
    torch.cuda.synchronize()
    sparse_two_step_time = (time.time() - start) / iterations * 1000
    
    print(f"   ç¨€ç–ä¸¤æ­¥æ€»æ—¶é—´: {sparse_two_step_time:.3f}ms")
    
    # 3. åˆ†è§£å¯¹æ¯”å„æ­¥
    print(f"\n3. åˆ†è§£å„æ­¥æ—¶é—´")
    
    # ç¬¬ä¸€æ­¥å•ç‹¬æµ‹è¯•
    for _ in range(warmup):
        _ = torch.matmul(x, weight_in_dense.t())
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = torch.matmul(x, weight_in_dense.t())
    torch.cuda.synchronize()
    dense_step1_time = (time.time() - start) / iterations * 1000
    
    for _ in range(warmup):
        _ = fp8_linear.apply(x, weight_in_sparse, None)
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = fp8_linear.apply(x, weight_in_sparse, None)
    torch.cuda.synchronize()
    sparse_step1_time = (time.time() - start) / iterations * 1000
    
    # ç¬¬äºŒæ­¥å•ç‹¬æµ‹è¯• (ä½¿ç”¨ä¸­é—´å°ºå¯¸)
    x_temp = torch.randn(batch_size, seq_len, rank).cuda()
    
    for _ in range(warmup):
        _ = torch.matmul(x_temp, weight_out_dense.t())
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = torch.matmul(x_temp, weight_out_dense.t())
    torch.cuda.synchronize()
    dense_step2_time = (time.time() - start) / iterations * 1000
    
    for _ in range(warmup):
        _ = fp8_linear.apply(x_temp, weight_out_sparse, None)
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(iterations):
        _ = fp8_linear.apply(x_temp, weight_out_sparse, None)
    torch.cuda.synchronize()
    sparse_step2_time = (time.time() - start) / iterations * 1000
    
    print(f"   ç¬¬ä¸€æ­¥ (768â†’64):")
    print(f"     å¯†é›†: {dense_step1_time:.3f}ms")
    print(f"     ç¨€ç–: {sparse_step1_time:.3f}ms (åŠ é€Ÿ: {dense_step1_time/sparse_step1_time:.2f}x)")
    
    print(f"   ç¬¬äºŒæ­¥ (64â†’3072):")
    print(f"     å¯†é›†: {dense_step2_time:.3f}ms")
    print(f"     ç¨€ç–: {sparse_step2_time:.3f}ms (åŠ é€Ÿ: {dense_step2_time/sparse_step2_time:.2f}x)")
    
    # 4. æ€»ç»“å¯¹æ¯”
    print(f"\n=== æ€»ç»“å¯¹æ¯” ===")
    print(f"è¿ç»­ä¸¤æ­¥æ€»æ—¶é—´:")
    print(f"  å¯†é›†: {dense_two_step_time:.3f}ms")
    print(f"  ç¨€ç–: {sparse_two_step_time:.3f}ms")
    print(f"  ç¨€ç–åŠ é€Ÿæ¯”: {dense_two_step_time/sparse_two_step_time:.2f}x")
    
    # å„æ­¥ç›¸åŠ  vs è¿ç»­æ“ä½œ
    theoretical_dense = dense_step1_time + dense_step2_time
    theoretical_sparse = sparse_step1_time + sparse_step2_time
    
    print(f"\nç†è®ºæ—¶é—´ (å„æ­¥ç›¸åŠ ) vs å®é™…æ—¶é—´:")
    print(f"  å¯†é›†ç†è®º: {theoretical_dense:.3f}ms vs å®é™…: {dense_two_step_time:.3f}ms (å·®å¼‚: {abs(theoretical_dense-dense_two_step_time):.3f}ms)")
    print(f"  ç¨€ç–ç†è®º: {theoretical_sparse:.3f}ms vs å®é™…: {sparse_two_step_time:.3f}ms (å·®å¼‚: {abs(theoretical_sparse-sparse_two_step_time):.3f}ms)")
    
    # æ£€æŸ¥ç¨€ç–åº¦
    sparsity_in = (weight_in_sparse == 0).float().mean().item()
    sparsity_out = (weight_out_sparse == 0).float().mean().item()
    print(f"\nç¨€ç–åº¦æ£€æŸ¥:")
    print(f"  ç¬¬ä¸€æ­¥æƒé‡ç¨€ç–åº¦: {sparsity_in:.1%}")
    print(f"  ç¬¬äºŒæ­¥æƒé‡ç¨€ç–åº¦: {sparsity_out:.1%}")
    
    return {
        'dense_two_step': dense_two_step_time,
        'sparse_two_step': sparse_two_step_time,
        'dense_step1': dense_step1_time,
        'sparse_step1': sparse_step1_time,
        'dense_step2': dense_step2_time,
        'sparse_step2': sparse_step2_time,
        'speedup': dense_two_step_time/sparse_two_step_time
    }

def main():
    print("ğŸ§ª ä½¿ç”¨æ­£ç¡®çš„soft_threshold24_tritonæµ‹è¯•2:4åŠ é€Ÿæ•ˆæœ")
    print("="*60)
    
    # æ£€æŸ¥GPUä¿¡æ¯
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"GPU: {gpu_name}")
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        return
    
    # éªŒè¯ç¨€ç–çŸ©é˜µåˆ›å»º
    test_sparse_creation()
    
    # å¯¹æ¯”é”™è¯¯ vs æ­£ç¡®çš„ç¨€ç–åˆ›å»ºæ–¹æ³•
    # compare_old_vs_new_sparse_creation()
    
    # æµ‹è¯•ä¸åŒå°ºå¯¸çš„çŸ©é˜µ (ä½¿ç”¨æ­£ç¡®æ–¹æ³•)
    print(f"\n" + "="*60)
    print("ä¸åŒçŸ©é˜µå°ºå¯¸æµ‹è¯• (ä½¿ç”¨æ­£ç¡®ç¨€ç–åˆ›å»º)")
    print("="*60)
    
    test_results = []
    
    # # å°çŸ©é˜µ (LOROçš„ç¬¬ä¸€æ­¥)
    # sparse_time, dense_time, speedup = test_matrix_size_performance_correct(768, 64, "å°çŸ©é˜µ")
    # test_results.append(("768Ã—64 (LOROç¬¬ä¸€æ­¥)", speedup))
    
    # # ä¸­å°çŸ©é˜µ (LOROçš„ç¬¬äºŒæ­¥)  
    # sparse_time, dense_time, speedup = test_matrix_size_performance_correct(64, 3072, "ä¸­å°çŸ©é˜µ")
    # test_results.append(("64Ã—3072 (LOROç¬¬äºŒæ­¥)", speedup))
    
    # # ä¸­ç­‰çŸ©é˜µ
    # sparse_time, dense_time, speedup = test_matrix_size_performance_correct(768, 256, "ä¸­ç­‰çŸ©é˜µ")
    # test_results.append(("768Ã—256", speedup))
    
    # # å¤§çŸ©é˜µ (åŸå§‹)
    # sparse_time, dense_time, speedup = test_matrix_size_performance_correct(768, 3072, "å¤§çŸ©é˜µ")
    # test_results.append(("768Ã—3072 (åŸå§‹)", speedup))
    
    # æ–°å¢ï¼šæµ‹è¯•è¿ç»­ä¸¤æ­¥æ“ä½œ
    two_step_results = test_two_step_matmul_comparison()
    
    # æ±‡æ€»ç»“æœ
    print(f"\n" + "="*60)
    print("ğŸ“‹ æ­£ç¡®ç¨€ç–åˆ›å»ºæ–¹æ³•çš„åŠ é€Ÿæ•ˆæœæ±‡æ€»")
    print("="*60)
    for name, speedup in test_results:
        status = "âœ…" if speedup > 1.2 else "âš ï¸ " if speedup > 0.9 else "âŒ"
        print(f"{status} {name:20} {speedup:.2f}x")
    
    # ä¸¤æ­¥æ“ä½œæ±‡æ€»
    speedup_two_step = two_step_results['speedup']
    status = "âœ…" if speedup_two_step > 1.2 else "âš ï¸ " if speedup_two_step > 0.9 else "âŒ"
    print(f"{status} è¿ç»­ä¸¤æ­¥æ“ä½œ:        {speedup_two_step:.2f}x")

if __name__ == "__main__":
    main() 