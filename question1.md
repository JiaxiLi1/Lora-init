- [ ] 我发现比如对于cola，如果我完全不开启activation 2:4训练的话训练就是正常，但如果我开启activation 2:4训练，比如即使我只是用squ_relu=relu2，不在lowrank中使用activation 2;4，训练也会很快变差，比如我用了这个训练命令--model_config configs/llama_130m.json --dtype bfloat16 --batch_size 64 --total_batch_size 512 --num_training_steps 20000 --save_every 5000 --eval_every 1000 --lr 0.001 --scheduler cosine_restart --warmup_steps 2000 --min_lr_ratio 0.1 --cosine_restart_freq 500 --lr_adjust_steps -2000 --weight_decay 0 --grad_clipping 0.5 --optimizer cola_adamw --loro_refresh all --loro_refresh_freq 500 --loro_scope all --loro_init xavier --loro_attn_rank 256 --loro_mlp_rank 256 --loro_type loro --loro_freq 500 --loro_lr_scaler -1 --c4_local False --enable_2to4_sparse False --attn_2by4 False --mlp_2by4 False --activation_soft_threshold False --activation_sparse_method naive --activation_dense_warmup_steps 1000 --dx_direct_sparse 3 --dynamic_activation_steps 200 --activation_calibration_samples 256 --momentum_reset_steps 0 --cola_sparse_method cola_init --more_activation_relu2 True --save_ckpt True --seed 43 --flip_rate True --activation_2by4 True --wandb_sparsityrelu True --squ_relu silu --permute_2by4 False就发现在一百多步后loss就跑飞了，而且打印出来的relu2后的sparsity直接变成0了，这是怎么回事？你能不能调查一下找到训练效果不好的真正原因？或者你能不能先分析一下是为什么会出现这个问题然后为什么loss会在一百多步（这里是178步）之后突然变成NaN?你能明白我的意思吗？